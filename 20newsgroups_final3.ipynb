{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Report\n",
    "\n",
    "Steven Hudler & Andrew Maybach\n",
    "\n",
    "Introduction\n",
    "\n",
    "\n",
    "The purpose of this project is to analyze how well-known different models perform on document classification. The models that will be used here are: Multinomial Bayes and Logistic Regression using Count Vectorizer and Tfidf Vectorizer. The dataset will be the twenty different topic based 1800 documents from sklearn's newsgroup. We will use the pandas dataframe, the nltk library, and sklearn's models with metrics. A variety of functions will be used through out this workbook.The first step was importing the necessary models and the fetch_20newsgroup from the sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/Envs/text/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/andy/Envs/text/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/andy/Envs/text/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import names\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = fetch_20newsgroups(subset='train', shuffle=True,random_state=123) # added random state\n",
    "testing_data = fetch_20newsgroups(subset='test', shuffle=True,random_state=123) # added random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newsgroup dataset are based on 20 topics from a sortment of different fields ranging from atheism to politics. The target/labels will be the 20 targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into a test and train split. Shuffle is a necessary step to make sure the documents are evenly distributed between the test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the data types of the train and test type. We transform the test and train into a pandas dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame({'Text': training_data.data, 'Label':training_data.target})\n",
    "testing = pd.DataFrame({'Text': testing_data.data, 'Label':testing_data.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: nextug@ac.dal.ca\\nSubject: Powerbook 140...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: kennejs@a.cs.okstate.edu (KENNEDY JAMES ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: robg@citr.uq.oz.au (Rob Geraghty)\\nSubje...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: eapu207@orion.oac.uci.edu (John Peter Ko...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: neal@cmptrc.lonestar.org (Neal Howard)\\n...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  From: nextug@ac.dal.ca\\nSubject: Powerbook 140...      4\n",
       "1  From: kennejs@a.cs.okstate.edu (KENNEDY JAMES ...     16\n",
       "2  From: robg@citr.uq.oz.au (Rob Geraghty)\\nSubje...     13\n",
       "3  From: eapu207@orion.oac.uci.edu (John Peter Ko...      1\n",
       "4  From: neal@cmptrc.lonestar.org (Neal Howard)\\n...     13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creating a function that will remove punctuation, lemmatize and remove names from the text. When vectorizing, stop words and lowercase transformation will be addressed to avoid redundancies and discrepancies in text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(docs):\n",
    "    '''This function lemmatizes texts and removes names'''\n",
    "    out= []\n",
    "    proper_names = names.words()\n",
    "    lemma = WordNetLemmatizer()\n",
    "    for words in docs.split():\n",
    "        if words.isalpha() and words not in proper_names:\n",
    "            out.append(lemma.lemmatize(words.lower())) \n",
    "        text = ' '.join(out)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the cleaned text column to both training and testing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['cleaned_text'] = training['Text'].apply(lambda x: clean_text(x))\n",
    "testing['cleaned_text'] = testing['Text'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only the cleaned text and labels in training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training[['cleaned_text','Label']]\n",
    "testing = testing[['cleaned_text','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not necessary but could be useful if the cleaned frame is needed elsewhere\n",
    "# pickle.dump(training,open('training_frame.pickle','wb'))\n",
    "# pickle.dump(testing,open('testing_frame.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = training['cleaned_text'],training['Label']\n",
    "x_test,y_test = testing['cleaned_text'],testing['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously experimented with different bag of words models and TFIDF performs consistently better than count vectorizer so for model testing we will be focusing on TFIDF. Below are the TFIDF parameters we will be testing on multiple models. The models are tested via pipeline and gridsearch over the aforementioned parameters. Gridsearch outputs a \"Best Score\" which is the best scoring on left out data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {'vect__max_features' : (100,1000, 2000, 8000),\n",
    "             'vect__max_df' : (0.25, 0.5),\n",
    "             'vect__smooth_idf' : (True, False),\n",
    "             'vect__sublinear_tf' : (True, False)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...rue,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'vect__max_features': (100, 1000, 2000, 8000), 'vect__max_df': (0.25, 0.5), 'vect__smooth_idf': (True, False), 'vect__sublinear_tf': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1 = Pipeline([('vect',TfidfVectorizer(stop_words= 'english')),('clf',MultinomialNB())])\n",
    "grid_search1 = grid_search = GridSearchCV(pipeline1, parms,cv = 3)\n",
    "grid_search1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8331270991691709"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = grid_search1.best_score_\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/Envs/text/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/andy/Envs/text/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'vect__max_features': (100, 1000, 2000, 8000), 'vect__max_df': (0.25, 0.5), 'vect__smooth_idf': (True, False), 'vect__sublinear_tf': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([('vect',TfidfVectorizer(stop_words= 'english')),('clf',LogisticRegression())])\n",
    "grid_search2 = grid_search = GridSearchCV(pipeline2, parms,cv = 3)\n",
    "grid_search2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469153261445996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = grid_search2.best_score_\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'vect__max_features': (100, 1000, 2000, 8000), 'vect__max_df': (0.25, 0.5), 'vect__smooth_idf': (True, False), 'vect__sublinear_tf': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3 = Pipeline([('vect',TfidfVectorizer(stop_words= 'english')),('clf',LinearSVC())])\n",
    "grid_search3 = GridSearchCV(pipeline3, parms,cv = 3)\n",
    "grid_search3.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713982676330211"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score3 = grid_search3.best_score_\n",
    "score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will test the data on our hold out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = grid_search1.predict(x_test)\n",
    "test2 = grid_search2.predict(x_test)\n",
    "test3 = grid_search3.predict(x_test)\n",
    "\n",
    "test_score1 = accuracy_score(test1,y_test)\n",
    "test_score2 = accuracy_score(test2,y_test)\n",
    "test_score3 = accuracy_score(test3,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the best scores and test data scores from the Niave Bayes, Logistic and Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>Test Data Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.833127</td>\n",
       "      <td>0.771641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.846915</td>\n",
       "      <td>0.774429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Support Vector Classifier</td>\n",
       "      <td>0.871398</td>\n",
       "      <td>0.779076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Best Scores  Test Data Scores\n",
       "0           Multinomial Naive Bayes     0.833127          0.771641\n",
       "1               Logistic Regression     0.846915          0.774429\n",
       "2  Linear Support Vector Classifier     0.871398          0.779076"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Model':['Multinomial Naive Bayes','Logistic Regression','Linear Support Vector Classifier'],\n",
    "             'Best Scores': [score1,score2,score3],\n",
    "             'Test Data Scores':[test_score1,test_score2,test_score3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above our best model is the Linear Support Vector Classifier. Full fit details below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_df': 0.25,\n",
       " 'vect__max_features': 8000,\n",
       " 'vect__smooth_idf': False,\n",
       " 'vect__sublinear_tf': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
