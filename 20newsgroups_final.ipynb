{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "testing_data = fetch_20newsgroups(subset='test', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame({'Text': training_data.data, 'Label':training_data.target})\n",
    "testing = pd.DataFrame({'Text': testing_data.data, 'Label':testing_data.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    rgx = re.compile(f'[{re.escape(string.punctuation)}]' )\n",
    "    text = rgx.sub('',text)\n",
    "    text= text.lower()\n",
    "    text = text.split('\\n')\n",
    "    text = ' '.join([x for x in text])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['cleaned_text'] = training['Text'].apply(lambda x: clean_text(x))\n",
    "testing['cleaned_text'] = testing['Text'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>from lerxstwamumdedu wheres my thing subject w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>from guykuocarsonuwashingtonedu guy kuo subjec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>from twillisececnpurdueedu thomas e willis sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>from jgreenamber joe green subject re weitek p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>from jcmheadcfaharvardedu jonathan mcdowell su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...      7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...      1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  from lerxstwamumdedu wheres my thing subject w...  \n",
       "1  from guykuocarsonuwashingtonedu guy kuo subjec...  \n",
       "2  from twillisececnpurdueedu thomas e willis sub...  \n",
       "3  from jgreenamber joe green subject re weitek p...  \n",
       "4  from jcmheadcfaharvardedu jonathan mcdowell su...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training[['cleaned_text','Label']]\n",
    "testing = testing[['cleaned_text','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = training['cleaned_text'],training['Label']\n",
    "x_test,y_test = testing['cleaned_text'],testing['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "tfidf = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "logistic = LogisticRegression()\n",
    "mnb = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(logistic_count_pipe,open('logistic_count.pickle','wb'))\n",
    "# # joblib.dump(logistic_count_pipe,'logistic_count.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_scoring(model):\n",
    "    scores = {}\n",
    "    preds = model.predict(x_test)\n",
    "    return accuracy_score(preds,y_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_count_pipe = Pipeline([('vectorizer',count),('classifier',logistic)])\n",
    "bayes_count_pipe = Pipeline([('vectorizer',count),('classifier',mnb)])\n",
    "logistic_tfidf_pipe = Pipeline([('vectorizer',tfidf),('classifier',logistic)])\n",
    "bayes_tfidf_pipe = Pipeline([('vectorizer',tfidf),('classifier',mnb)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/Envs/text/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/andy/Envs/text/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/andy/Envs/text/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/andy/Envs/text/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_names = ['logistic(1,2)_with_countVect','bayes(1,2)_with_countVect', 'logistic(1,2)_with_TFIDF','bayes(1,2)_with_TFIDF']\n",
    "models = [logistic_count_pipe,bayes_count_pipe,logistic_tfidf_pipe,bayes_tfidf_pipe]\n",
    "accuracy_scores={}\n",
    "\n",
    "for idx,model in enumerate(models):\n",
    "    model = model.fit(x_train,y_train)\n",
    "    pickle.dump(model,open(f'{model_names[idx]}.pickle','wb'))\n",
    "    accuracy_scores[model_names[idx]] = accuracy_scoring(model)\n",
    "    del model # to negate memory error\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic(1,2)_with_countVect': 0.8244822092405736,\n",
       " 'bayes(1,2)_with_countVect': 0.8323154540626659,\n",
       " 'logistic(1,2)_with_TFIDF': 0.8347052575677111,\n",
       " 'bayes(1,2)_with_TFIDF': 0.830323951141795}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle.dump(bayes_count_pipe,open('bayes_count.pickle','wb'))\n",
    "# joblib.dump(bayes_count_pipe,'bayes_count.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle.dump(logistic_tfidf_pipe,open('logistic_tfidf.pickle','wb'))\n",
    "# joblib.dump(logistic_tfidf_pipe,'logisitic_tfidf.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle.dump(bayes_tfidf_pipe,open('bayes_tfidf.pickle','wb'))\n",
    "# joblib.dump(bayes_tfidf_pipe,'bayes_tfidf.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_classifiers(models,model_names,x_test=x_test,y_test=y_test):\n",
    "    \n",
    "#     accuracies = []\n",
    "#     precisions = []\n",
    "#     recalls  = []\n",
    "#     for mods in models:\n",
    "#         preds = mods.predict(x_test)\n",
    "#         accuracies.append(accuracy_score(preds,y_test))\n",
    "#         precisions.append (precision_score(preds, y_test))\n",
    "#         recalls.append(recall_score(preds,y_test))\n",
    "#     return pd.DataFrame([accuracies,precisions,recalls],\n",
    "#                         columns = ['accuracy','precision','recall'],\n",
    "#                         index=model_names)\n",
    "        \n",
    "# compare_classifiers(models,model names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords? punctuation? abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count = CountVectorizer(stop_words='english')\n",
    "# # tfidf = TfidfVectorizer(stop_words='english')\n",
    "# # logistic = LogisticRegression()\n",
    "# # mnb = MultinomialNB()\n",
    "\n",
    "\n",
    "# ngrams_list =[(1,1)]\n",
    "# def vect_test(vectorizer,\n",
    "#               classifier,\n",
    "#               ngrams_list,\n",
    "#               x_train=x_train,\n",
    "#               y_train=y_train,\n",
    "#               x_test=x_test,\n",
    "#               y_test=y_test):\n",
    "#     scores = {}\n",
    "#     for n in ngrams_list:\n",
    "#         vect = vectorizer.set_params(stop_words='english',ngram_range=n)\n",
    "#         pipe = Pipeline([('vectorizer',vect),('classifier',classifier)])\n",
    "#         mod = pipe.fit(x_train,y_train)\n",
    "#         preds = mod.predict(x_test)\n",
    "#         score = accuracy_score(preds,y_test)\n",
    "#         scores[f'vectorizer{vectorizer}:ngrams{n}']=score\n",
    "#     return scores\n",
    "        \n",
    "# vect_test(CountVectorizer(),LogisticRegression(),ngrams_list)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
